{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_pil_contract, split_into_rows\n",
    "\n",
    "\n",
    "image = get_pil_contract(\"1\", \"1\")\n",
    "rows = split_into_rows(image, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.47.1\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 1024,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoImageProcessor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize processors and model\n",
    "trocr_processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "bollinger_image_processor = AutoImageProcessor.from_pretrained(\n",
    "    \"pstroe/bullinger-general-model\"\n",
    ")\n",
    "bollinger_model = VisionEncoderDecoderModel.from_pretrained(\n",
    "    \"pstroe/bullinger-general-model\"\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "bollinger_model = bollinger_model.to(device)\n",
    "\n",
    "\n",
    "@torch.no_grad()  # Optimization for inference\n",
    "def process_batch(batch_rois, batch_indices, ocr_proc, htr_model, htr_proc):\n",
    "    # Convert all ROIs to PIL Images in batch\n",
    "    roi_pils = [Image.fromarray(roi).convert(\"RGB\") for roi in batch_rois]\n",
    "\n",
    "    # Process entire batch at once\n",
    "    pixel_values = htr_proc(\n",
    "        images=roi_pils, return_tensors=\"pt\", padding=True\n",
    "    ).pixel_values.to(device)\n",
    "\n",
    "    generated_ids = htr_model.generate(pixel_values)\n",
    "    texts = ocr_proc.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    return list(zip(texts, [idx + 1 for idx in batch_indices]))\n",
    "\n",
    "\n",
    "def process_image(image, rows):\n",
    "    # Collect all ROIs and their corresponding row indices\n",
    "    rois = []\n",
    "    row_indices = []\n",
    "\n",
    "    # Iterate through rows\n",
    "    for row_idx, row in enumerate(tqdm(rows, desc=\"Processing rows\")):\n",
    "        for (x, y), contour in row.items():\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            roi = image[y : y + h, x : x + w]\n",
    "            rois.append(roi)\n",
    "            row_indices.append(row_idx)\n",
    "\n",
    "    # Process in batches\n",
    "    BATCH_SIZE = 16  # Adjust based on your GPU memory\n",
    "    batched_rois = [rois[i : i + BATCH_SIZE] for i in range(0, len(rois), BATCH_SIZE)]\n",
    "    batched_indices = [\n",
    "        row_indices[i : i + BATCH_SIZE] for i in range(0, len(row_indices), BATCH_SIZE)\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nProcessing {len(rois)} ROIs in {len(batched_rois)} batches...\")\n",
    "\n",
    "    # Use ThreadPoolExecutor for batch processing\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        futures = []\n",
    "        for batch_roi, batch_idx in zip(batched_rois, batched_indices):\n",
    "            future = executor.submit(\n",
    "                process_batch,\n",
    "                batch_roi,\n",
    "                batch_idx,\n",
    "                trocr_processor,\n",
    "                bollinger_model,\n",
    "                bollinger_image_processor,\n",
    "            )\n",
    "            futures.append(future)\n",
    "\n",
    "        # Collect results\n",
    "        results = []\n",
    "        for future in futures:\n",
    "            results.extend(future.result())\n",
    "\n",
    "    print(\"\\nSorting results...\")\n",
    "    return sorted(results, key=lambda x: x[1])  # Sort by row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, row_num \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 44\u001b[0m, in \u001b[0;36mprocess_image\u001b[0;34m(image, rows)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Iterate through rows\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_idx, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(rows, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing rows\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (x, y), contour \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     45\u001b[0m         x, y, w, h \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mboundingRect(contour)\n\u001b[1;32m     46\u001b[0m         roi \u001b[38;5;241m=\u001b[39m image[y : y \u001b[38;5;241m+\u001b[39m h, x : x \u001b[38;5;241m+\u001b[39m w]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "results = process_image(image, rows)\n",
    "for text, row_num in results:\n",
    "    print(f\"Row {row_num}: {text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
